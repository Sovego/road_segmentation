{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "! pip install segmentation-models-pytorch"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2023-05-16T10:31:27.499198Z",
     "iopub.execute_input": "2023-05-16T10:31:27.499947Z",
     "iopub.status.idle": "2023-05-16T10:31:44.805615Z",
     "shell.execute_reply.started": "2023-05-16T10:31:27.499914Z",
     "shell.execute_reply": "2023-05-16T10:31:44.804369Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": "Collecting segmentation-models-pytorch\n  Downloading segmentation_models_pytorch-0.3.2-py3-none-any.whl (106 kB)\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m106.7/106.7 kB\u001B[0m \u001B[31m4.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (4.64.1)\nCollecting timm==0.6.12\n  Downloading timm-0.6.12-py3-none-any.whl (549 kB)\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m549.1/549.1 kB\u001B[0m \u001B[31m24.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hCollecting pretrainedmodels==0.7.4\n  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m58.8/58.8 kB\u001B[0m \u001B[31m6.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25ldone\n\u001B[?25hCollecting efficientnet-pytorch==0.7.1\n  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n  Preparing metadata (setup.py) ... \u001B[?25ldone\n\u001B[?25hRequirement already satisfied: torchvision>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.15.1)\nRequirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (9.5.0)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.0.0)\nRequirement already satisfied: munch in /opt/conda/lib/python3.10/site-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch) (2.5.0)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm==0.6.12->segmentation-models-pytorch) (6.0)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from timm==0.6.12->segmentation-models-pytorch) (0.13.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (2.28.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (1.23.5)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.1.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (4.5.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.11.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.11.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm==0.6.12->segmentation-models-pytorch) (21.3)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from munch->pretrainedmodels==0.7.4->segmentation-models-pytorch) (1.16.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (2.1.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (2022.12.7)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (3.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub->timm==0.6.12->segmentation-models-pytorch) (3.0.9)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.1.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.3.0)\nBuilding wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n  Building wheel for efficientnet-pytorch (setup.py) ... \u001B[?25ldone\n\u001B[?25h  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16446 sha256=6bd2afb9d6ab838a35c0761b32e8a3a7dbca7a3150e9002e7a0b1769a21fd437\n  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n  Building wheel for pretrainedmodels (setup.py) ... \u001B[?25ldone\n\u001B[?25h  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60966 sha256=84a35685b79d7fb8906cb608de5220dfe720e8fbf29785afed97a4bf69784aaf\n  Stored in directory: /root/.cache/pip/wheels/35/cb/a5/8f534c60142835bfc889f9a482e4a67e0b817032d9c6883b64\nSuccessfully built efficientnet-pytorch pretrainedmodels\nInstalling collected packages: efficientnet-pytorch, timm, pretrainedmodels, segmentation-models-pytorch\n  Attempting uninstall: timm\n    Found existing installation: timm 0.6.13\n    Uninstalling timm-0.6.13:\n      Successfully uninstalled timm-0.6.13\nSuccessfully installed efficientnet-pytorch-0.7.1 pretrainedmodels-0.7.4 segmentation-models-pytorch-0.3.2 timm-0.6.12\n\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n\u001B[0m",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "from os.path import join as pjoin\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "import torchmetrics.classification as metrics\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torchinfo\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-16T10:31:44.809295Z",
     "iopub.execute_input": "2023-05-16T10:31:44.809652Z",
     "iopub.status.idle": "2023-05-16T10:31:47.816812Z",
     "shell.execute_reply.started": "2023-05-16T10:31:44.809623Z",
     "shell.execute_reply": "2023-05-16T10:31:47.815762Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "from os.path import join as pjoin\n",
    "import contextlib\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def uniqufy_path(path):\n",
    "    filename, extension = os.path.splitext(path)\n",
    "    file_index = 1\n",
    "\n",
    "    while os.path.exists(path):\n",
    "        path = f\"{filename}_{file_index}{extension}\"\n",
    "        file_index += 1\n",
    "    \n",
    "    return path\n",
    "\n",
    "def create_image_plot(row_len : int = None, figsize = (16,6), **images):\n",
    "    n_images = len(images)\n",
    "    if row_len is None:\n",
    "        row_len = n_images\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    for idx, (name, image) in enumerate(images.items()):\n",
    "        #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        ax = fig.add_subplot(n_images//row_len+1, row_len, idx+1)\n",
    "        ax.set_title(name.title(), fontsize=16)\n",
    "        with open(\"/dev/null\", 'w') as dummy_f:\n",
    "            with contextlib.redirect_stderr(dummy_f):\n",
    "                ax.imshow(image)\n",
    "    return fig\n",
    "\n",
    "def save_imgs(path = None, name = \"imgs\", **images):\n",
    "    if(path is None):\n",
    "        raise AttributeError(f\"You shoud write path\")\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    image_path = pjoin(path, f\"{name}\")\n",
    "    fig = create_image_plot(**images)\n",
    "    fig.savefig(image_path)\n",
    "    fig.clear()\n",
    "    plt.close(fig)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-16T10:31:47.818059Z",
     "iopub.execute_input": "2023-05-16T10:31:47.818414Z",
     "iopub.status.idle": "2023-05-16T10:31:47.831201Z",
     "shell.execute_reply.started": "2023-05-16T10:31:47.818362Z",
     "shell.execute_reply": "2023-05-16T10:31:47.829980Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "LAUNCH_NAME = \"UNet_9\"\n",
    "\n",
    "\n",
    "STARTING_EPOCH = 0\n",
    "LOAD_WEIGHTS = None #\n",
    "LOAD_ADAM_STATE = None #\n",
    "USE_MANUAL_TENSORBOARD_FOLDER = None # \n",
    "\n",
    "SAVED_MODEL_PATH = None \n",
    "\n",
    "EPOCHS = 15\n",
    "LEARNING_RATE = 1E-5 # 0.0001 \n",
    "WEIGHT_DECAY = 0 # 1E-7\n",
    "\n",
    "BATCH_SIZE = 10 # 20\n",
    "\n",
    "SAVE_METHOD = \"TORCH\" # \"TORCH\" / \"ONNX\"\n",
    "WEIGHT_SAVER = \"last\" # \"all\" / \"nothing\" / \"last\"\n",
    "\n",
    "CLASS_NAMES = ['other', 'road']\n",
    "CLASS_RGB_VALUES = [[0,0,0], [255, 255, 255]]\n",
    "\n",
    "NORMALIZE_MEAN_IMG =  [0.4295, 0.4325, 0.3961]       #[0.485, 0.456, 0.406]\n",
    "NORMALIZE_DEVIATIONS_IMG =  [0.2267, 0.2192, 0.2240] #[0.229, 0.224, 0.225]\n",
    " \n",
    "CROP_SIZE = (256, 256)\n",
    "\n",
    "NUM_WORKERS = 2\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "DATASET_DIR = '/kaggle/input/massachusetts-roads-dataset/tiff'\n",
    "VALID_SET   = (pjoin(DATASET_DIR, \"val\"), pjoin(DATASET_DIR, \"val_labels\"))\n",
    "TEST_SET   =  (pjoin(DATASET_DIR, \"test\"), pjoin(DATASET_DIR, \"test_labels\"))\n",
    "TRAIN_SET   = (pjoin(DATASET_DIR, \"train\"), pjoin(DATASET_DIR, \"train_labels\"))\n",
    "\n",
    "trained = False"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-16T10:31:47.835259Z",
     "iopub.execute_input": "2023-05-16T10:31:47.836245Z",
     "iopub.status.idle": "2023-05-16T10:31:47.871485Z",
     "shell.execute_reply.started": "2023-05-16T10:31:47.836206Z",
     "shell.execute_reply": "2023-05-16T10:31:47.870454Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "TBpath = uniqufy_path(f\"TB_cache/{LAUNCH_NAME}\") if USE_MANUAL_TENSORBOARD_FOLDER is None else USE_MANUAL_TENSORBOARD_FOLDER\n",
    "TBwriter = SummaryWriter(TBpath)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-16T10:31:47.873332Z",
     "iopub.execute_input": "2023-05-16T10:31:47.873970Z",
     "iopub.status.idle": "2023-05-16T10:31:47.886795Z",
     "shell.execute_reply.started": "2023-05-16T10:31:47.873936Z",
     "shell.execute_reply": "2023-05-16T10:31:47.885819Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def to_tensor(x, **kwargs):\n",
    "    return x.transpose(2, 0, 1).astype('float32')\n",
    "\n",
    "prepare_to_network = A.Lambda(image=to_tensor, mask=to_tensor)\n",
    "\n",
    "train_transform = A.Compose(\n",
    "    [\n",
    "        A.OneOf(\n",
    "            [\n",
    "                A.HorizontalFlip(p=1),\n",
    "                A.VerticalFlip(p=1),\n",
    "                A.RandomRotate90(p=1),\n",
    "            ],\n",
    "            p=0.75,\n",
    "        ),\n",
    "        A.Normalize(mean=NORMALIZE_MEAN_IMG, std=NORMALIZE_DEVIATIONS_IMG, always_apply=True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "valid_transform = A.Compose(\n",
    "    [\n",
    "        A.Normalize(mean=NORMALIZE_MEAN_IMG, std=NORMALIZE_DEVIATIONS_IMG, always_apply=True),\n",
    "    ]\n",
    ")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-16T10:31:47.890138Z",
     "iopub.execute_input": "2023-05-16T10:31:47.890407Z",
     "iopub.status.idle": "2023-05-16T10:31:47.900460Z",
     "shell.execute_reply.started": "2023-05-16T10:31:47.890368Z",
     "shell.execute_reply": "2023-05-16T10:31:47.899580Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def one_hot_encode(label, label_values):\n",
    "    semantic_map = []\n",
    "    for colour in label_values:\n",
    "        equality = np.equal(label, colour)\n",
    "        class_map = np.all(equality, axis = -1)\n",
    "        semantic_map.append(class_map)\n",
    "    semantic_map = np.stack(semantic_map, axis=-1)\n",
    "    return semantic_map\n",
    "\n",
    "def reverse_one_hot(image):\n",
    "    x = np.argmax(image, axis = -1)\n",
    "    return x\n",
    "\n",
    "def colour_code_segmentation(image, label_values):\n",
    "    colour_codes = np.array(label_values)\n",
    "    x = colour_codes[image.astype(int)]\n",
    "    return x"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-16T10:31:47.902412Z",
     "iopub.execute_input": "2023-05-16T10:31:47.903033Z",
     "iopub.status.idle": "2023-05-16T10:31:47.910278Z",
     "shell.execute_reply.started": "2023-05-16T10:31:47.902994Z",
     "shell.execute_reply": "2023-05-16T10:31:47.909327Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class RoadsDataset(Dataset):\n",
    "    def __init__(self, values_dir, labels_dir, class_rgb_values=None, transform=None, readyToNetwork=None):\n",
    "        self.values_dir = values_dir\n",
    "        self.labels_dir = labels_dir\n",
    "        self.class_rgb_values = class_rgb_values\n",
    "        self.images = [pjoin(self.values_dir, filename) for filename in sorted(os.listdir(self.values_dir))]\n",
    "        self.labels = [pjoin(self.labels_dir, filename) for filename in sorted(os.listdir(self.labels_dir))]\n",
    "        self.transform = transform\n",
    "        self.readyToNetwork = readyToNetwork\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.images[index]\n",
    "        label_path = self.labels[index]\n",
    "\n",
    "        image = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n",
    "        label = cv2.cvtColor(cv2.imread(label_path), cv2.COLOR_BGR2RGB)\n",
    "        label = one_hot_encode(label, self.class_rgb_values).astype('float')\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(image=image, mask=label)\n",
    "            image, label = sample['image'], sample['mask']\n",
    "        if self.readyToNetwork:\n",
    "            sample = self.readyToNetwork(image=image, mask=label)\n",
    "            image, label = sample['image'], sample['mask']\n",
    "        return image, label"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-16T10:31:47.911836Z",
     "iopub.execute_input": "2023-05-16T10:31:47.912204Z",
     "iopub.status.idle": "2023-05-16T10:31:47.925353Z",
     "shell.execute_reply.started": "2023-05-16T10:31:47.912172Z",
     "shell.execute_reply": "2023-05-16T10:31:47.924297Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "sample_dataset = RoadsDataset(*TEST_SET,\n",
    "                       class_rgb_values=CLASS_RGB_VALUES, transform=valid_transform)\n",
    "\n",
    "for i in range(10):\n",
    "    image, mask = sample_dataset[np.random.randint(0, len(sample_dataset))]\n",
    "    TBwriter.add_figure(f'train samples', create_image_plot(origin=image, true=colour_code_segmentation(\n",
    "        reverse_one_hot(mask), CLASS_RGB_VALUES)), global_step=i)\n",
    "del(sample_dataset)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-16T10:31:47.926854Z",
     "iopub.execute_input": "2023-05-16T10:31:47.927368Z",
     "iopub.status.idle": "2023-05-16T10:31:58.033961Z",
     "shell.execute_reply.started": "2023-05-16T10:31:47.927338Z",
     "shell.execute_reply": "2023-05-16T10:31:58.013385Z"
    },
    "trusted": true
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\" Parts of the U-Net model \"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-16T10:31:58.038632Z",
     "iopub.execute_input": "2023-05-16T10:31:58.039190Z",
     "iopub.status.idle": "2023-05-16T10:31:58.055468Z",
     "shell.execute_reply.started": "2023-05-16T10:31:58.039151Z",
     "shell.execute_reply": "2023-05-16T10:31:58.054424Z"
    },
    "trusted": true
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\" Full assembly of the parts to form the complete network \"\"\"\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=False):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = (DoubleConv(n_channels, 64))\n",
    "        self.down1 = (Down(64, 128))\n",
    "        self.down2 = (Down(128, 256))\n",
    "        self.down3 = (Down(256, 512))\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = (Down(512, 1024 // factor))\n",
    "        self.up1 = (Up(1024, 512 // factor, bilinear))\n",
    "        self.up2 = (Up(512, 256 // factor, bilinear))\n",
    "        self.up3 = (Up(256, 128 // factor, bilinear))\n",
    "        self.up4 = (Up(128, 64, bilinear))\n",
    "        self.outc = (OutConv(64, n_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-16T10:31:58.056976Z",
     "iopub.execute_input": "2023-05-16T10:31:58.057380Z",
     "iopub.status.idle": "2023-05-16T10:31:58.070318Z",
     "shell.execute_reply.started": "2023-05-16T10:31:58.057348Z",
     "shell.execute_reply": "2023-05-16T10:31:58.069440Z"
    },
    "trusted": true
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model = UNet(3,2,bilinear=True)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-16T10:31:58.073532Z",
     "iopub.execute_input": "2023-05-16T10:31:58.074483Z",
     "iopub.status.idle": "2023-05-16T10:31:58.231481Z",
     "shell.execute_reply.started": "2023-05-16T10:31:58.074456Z",
     "shell.execute_reply": "2023-05-16T10:31:58.230450Z"
    },
    "trusted": true
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_dataset = RoadsDataset(*TRAIN_SET,\n",
    "                       class_rgb_values=CLASS_RGB_VALUES, transform=train_transform, readyToNetwork=prepare_to_network)\n",
    "valid_dataset = RoadsDataset(*VALID_SET,\n",
    "                       class_rgb_values=CLASS_RGB_VALUES, transform=valid_transform, readyToNetwork=prepare_to_network)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    ")\n",
    "valid_dataloader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=BATCH_SIZE//4,\n",
    "    num_workers=NUM_WORKERS,\n",
    ")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-16T10:31:58.233993Z",
     "iopub.execute_input": "2023-05-16T10:31:58.234978Z",
     "iopub.status.idle": "2023-05-16T10:31:58.524866Z",
     "shell.execute_reply.started": "2023-05-16T10:31:58.234939Z",
     "shell.execute_reply": "2023-05-16T10:31:58.523909Z"
    },
    "trusted": true
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# images, _ = next(iter(valid_dataloader))\n",
    "# TBwriter.add_graph(model, images)\n",
    "\n",
    "if \"ONNX\" in SAVE_METHOD:\n",
    "    model_path = f\"{TBpath}/model_first.onnx\"\n",
    "    torch.onnx.export(model, torch.empty(size=(BATCH_SIZE, 3, *CROP_SIZE)), model_path)\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "print(model_sum := torchinfo.summary(model, input_size=(BATCH_SIZE, 3, *CROP_SIZE), row_settings=[\"var_names\"], verbose=0, col_names=[\n",
    "      \"input_size\", \"output_size\", \"num_params\", \"params_percent\", \"kernel_size\", \"mult_adds\", \"trainable\"]))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-16T10:31:58.527587Z",
     "iopub.execute_input": "2023-05-16T10:31:58.527951Z",
     "iopub.status.idle": "2023-05-16T10:32:05.568288Z",
     "shell.execute_reply.started": "2023-05-16T10:31:58.527917Z",
     "shell.execute_reply": "2023-05-16T10:32:05.567354Z"
    },
    "trusted": true
   },
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "text": "============================================================================================================================================================================================================================\nLayer (type (var_name))                       Input Shape               Output Shape              Param #                   Param %                   Kernel Shape              Mult-Adds                 Trainable\n============================================================================================================================================================================================================================\nUNet (UNet)                                   [10, 3, 256, 256]         [10, 2, 256, 256]         --                             --                   --                        --                        True\n├─DoubleConv (inc)                            [10, 3, 256, 256]         [10, 64, 256, 256]        --                             --                   --                        --                        True\n│    └─Sequential (double_conv)               [10, 3, 256, 256]         [10, 64, 256, 256]        --                             --                   --                        --                        True\n│    │    └─Conv2d (0)                        [10, 3, 256, 256]         [10, 64, 256, 256]        1,728                       0.01%                   [3, 3]                    1,132,462,080             True\n│    │    └─BatchNorm2d (1)                   [10, 64, 256, 256]        [10, 64, 256, 256]        128                         0.00%                   --                        1,280                     True\n│    │    └─ReLU (2)                          [10, 64, 256, 256]        [10, 64, 256, 256]        --                             --                   --                        --                        --\n│    │    └─Conv2d (3)                        [10, 64, 256, 256]        [10, 64, 256, 256]        36,864                      0.21%                   [3, 3]                    24,159,191,040            True\n│    │    └─BatchNorm2d (4)                   [10, 64, 256, 256]        [10, 64, 256, 256]        128                         0.00%                   --                        1,280                     True\n│    │    └─ReLU (5)                          [10, 64, 256, 256]        [10, 64, 256, 256]        --                             --                   --                        --                        --\n├─Down (down1)                                [10, 64, 256, 256]        [10, 128, 128, 128]       --                             --                   --                        --                        True\n│    └─Sequential (maxpool_conv)              [10, 64, 256, 256]        [10, 128, 128, 128]       --                             --                   --                        --                        True\n│    │    └─MaxPool2d (0)                     [10, 64, 256, 256]        [10, 64, 128, 128]        --                             --                   2                         --                        --\n│    │    └─DoubleConv (1)                    [10, 64, 128, 128]        [10, 128, 128, 128]       221,696                     1.28%                   --                        36,238,791,680            True\n├─Down (down2)                                [10, 128, 128, 128]       [10, 256, 64, 64]         --                             --                   --                        --                        True\n│    └─Sequential (maxpool_conv)              [10, 128, 128, 128]       [10, 256, 64, 64]         --                             --                   --                        --                        True\n│    │    └─MaxPool2d (0)                     [10, 128, 128, 128]       [10, 128, 64, 64]         --                             --                   2                         --                        --\n│    │    └─DoubleConv (1)                    [10, 128, 64, 64]         [10, 256, 64, 64]         885,760                     5.13%                   --                        36,238,796,800            True\n├─Down (down3)                                [10, 256, 64, 64]         [10, 512, 32, 32]         --                             --                   --                        --                        True\n│    └─Sequential (maxpool_conv)              [10, 256, 64, 64]         [10, 512, 32, 32]         --                             --                   --                        --                        True\n│    │    └─MaxPool2d (0)                     [10, 256, 64, 64]         [10, 256, 32, 32]         --                             --                   2                         --                        --\n│    │    └─DoubleConv (1)                    [10, 256, 32, 32]         [10, 512, 32, 32]         3,540,992                  20.51%                   --                        36,238,807,040            True\n├─Down (down4)                                [10, 512, 32, 32]         [10, 512, 16, 16]         --                             --                   --                        --                        True\n│    └─Sequential (maxpool_conv)              [10, 512, 32, 32]         [10, 512, 16, 16]         --                             --                   --                        --                        True\n│    │    └─MaxPool2d (0)                     [10, 512, 32, 32]         [10, 512, 16, 16]         --                             --                   2                         --                        --\n│    │    └─DoubleConv (1)                    [10, 512, 16, 16]         [10, 512, 16, 16]         4,720,640                  27.35%                   --                        12,079,616,000            True\n├─Up (up1)                                    [10, 512, 16, 16]         [10, 256, 32, 32]         --                             --                   --                        --                        True\n│    └─Upsample (up)                          [10, 512, 16, 16]         [10, 512, 32, 32]         --                             --                   --                        --                        --\n│    └─DoubleConv (conv)                      [10, 1024, 32, 32]        [10, 256, 32, 32]         --                             --                   --                        --                        True\n│    │    └─Sequential (double_conv)          [10, 1024, 32, 32]        [10, 256, 32, 32]         5,899,776                  34.18%                   --                        60,397,992,960            True\n├─Up (up2)                                    [10, 256, 32, 32]         [10, 128, 64, 64]         --                             --                   --                        --                        True\n│    └─Upsample (up)                          [10, 256, 32, 32]         [10, 256, 64, 64]         --                             --                   --                        --                        --\n│    └─DoubleConv (conv)                      [10, 512, 64, 64]         [10, 128, 64, 64]         --                             --                   --                        --                        True\n│    │    └─Sequential (double_conv)          [10, 512, 64, 64]         [10, 128, 64, 64]         1,475,328                   8.55%                   --                        60,397,985,280            True\n├─Up (up3)                                    [10, 128, 64, 64]         [10, 64, 128, 128]        --                             --                   --                        --                        True\n│    └─Upsample (up)                          [10, 128, 64, 64]         [10, 128, 128, 128]       --                             --                   --                        --                        --\n│    └─DoubleConv (conv)                      [10, 256, 128, 128]       [10, 64, 128, 128]        --                             --                   --                        --                        True\n│    │    └─Sequential (double_conv)          [10, 256, 128, 128]       [10, 64, 128, 128]        369,024                     2.14%                   --                        60,397,981,440            True\n├─Up (up4)                                    [10, 64, 128, 128]        [10, 64, 256, 256]        --                             --                   --                        --                        True\n│    └─Upsample (up)                          [10, 64, 128, 128]        [10, 64, 256, 256]        --                             --                   --                        --                        --\n│    └─DoubleConv (conv)                      [10, 128, 256, 256]       [10, 64, 256, 256]        --                             --                   --                        --                        True\n│    │    └─Sequential (double_conv)          [10, 128, 256, 256]       [10, 64, 256, 256]        110,848                     0.64%                   --                        72,477,575,680            True\n├─OutConv (outc)                              [10, 64, 256, 256]        [10, 2, 256, 256]         --                             --                   --                        --                        True\n│    └─Conv2d (conv)                          [10, 64, 256, 256]        [10, 2, 256, 256]         130                         0.00%                   [1, 1]                    85,196,800                True\n============================================================================================================================================================================================================================\nTotal params: 17,263,042\nTrainable params: 17,263,042\nNon-trainable params: 0\nTotal mult-adds (G): 399.84\n============================================================================================================================================================================================================================\nInput size (MB): 7.86\nForward/backward pass size (MB): 4791.99\nParams size (MB): 69.05\nEstimated Total Size (MB): 4868.91\n============================================================================================================================================================================================================================\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "/opt/conda/lib/python3.10/site-packages/torchinfo/torchinfo.py:477: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  action_fn=lambda data: sys.getsizeof(data.storage()),\n/opt/conda/lib/python3.10/site-packages/torch/storage.py:665: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return super().__sizeof__() + self.nbytes()\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "loss = smp.losses.DiceLoss(mode='binary')\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                              lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=3, threshold=1e-3, cooldown=1, factor=0.5)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-16T10:32:05.569904Z",
     "iopub.execute_input": "2023-05-16T10:32:05.570593Z",
     "iopub.status.idle": "2023-05-16T10:32:05.577560Z",
     "shell.execute_reply.started": "2023-05-16T10:32:05.570542Z",
     "shell.execute_reply": "2023-05-16T10:32:05.576612Z"
    },
    "trusted": true
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def train_step(net, criterion, optimizer, dataloader, epoch: int = None):\n",
    "    net.train()\n",
    "    running_loss = 0.\n",
    "    for images, labels in dataloader:\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = net(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss\n",
    "\n",
    "    with torch.no_grad():\n",
    "        train_loss = running_loss / len(dataloader)\n",
    "    return train_loss.item()\n",
    "\n",
    "\n",
    "def valid_step(net, criterion, dataloader, epoch: int = None):\n",
    "    net.eval()\n",
    "    running_loss = 0.\n",
    "    IoU = metrics.BinaryJaccardIndex()\n",
    "    IoU.to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for step, (images, labels) in enumerate(dataloader):\n",
    "            images = images.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "\n",
    "            output = net(images)\n",
    "\n",
    "            IoU(output, labels)\n",
    "            loss = criterion(output, labels)\n",
    "            running_loss += loss\n",
    "\n",
    "            save_imgs(pjoin(TBpath, f\"valid_samples/samples_{epoch}\"), name=f\"img_{step}\",\n",
    "                origin=images[0].cpu().numpy().transpose(2, 1, 0),\n",
    "                true=colour_code_segmentation(reverse_one_hot(\n",
    "                    labels[0].cpu().numpy().transpose(2, 1, 0)), CLASS_RGB_VALUES),\n",
    "                pred=colour_code_segmentation(reverse_one_hot(\n",
    "                    output[0].cpu().numpy().transpose(2, 1, 0)), CLASS_RGB_VALUES))\n",
    "\n",
    "        TBwriter.add_figure('valid_sample', create_image_plot(\n",
    "                origin=images[0].cpu().numpy().transpose(2, 1, 0),\n",
    "                true=colour_code_segmentation(reverse_one_hot(\n",
    "                    labels[0].cpu().numpy().transpose(2, 1, 0)), CLASS_RGB_VALUES),\n",
    "                pred=colour_code_segmentation(reverse_one_hot(\n",
    "                    output[0].cpu().numpy().transpose(2, 1, 0)), CLASS_RGB_VALUES)),\n",
    "                  epoch)\n",
    "\n",
    "        valid_loss = running_loss / len(valid_dataloader)\n",
    "\n",
    "        return valid_loss.item(), IoU.compute().item()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-16T10:32:05.578787Z",
     "iopub.execute_input": "2023-05-16T10:32:05.579291Z",
     "iopub.status.idle": "2023-05-16T10:32:05.593681Z",
     "shell.execute_reply.started": "2023-05-16T10:32:05.579259Z",
     "shell.execute_reply": "2023-05-16T10:32:05.592799Z"
    },
    "trusted": true
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "epoch = STARTING_EPOCH"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-16T10:32:05.594763Z",
     "iopub.execute_input": "2023-05-16T10:32:05.595309Z",
     "iopub.status.idle": "2023-05-16T10:32:05.607525Z",
     "shell.execute_reply.started": "2023-05-16T10:32:05.595278Z",
     "shell.execute_reply": "2023-05-16T10:32:05.606695Z"
    },
    "trusted": true
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "best_loss = 10000\n",
    "trained = True\n",
    "\n",
    "pbar = tqdm(range(EPOCHS))\n",
    "pbar.update(epoch)\n",
    "\n",
    "while(epoch < EPOCHS):\n",
    "    train_loss = train_step(model, loss, optimizer, train_dataloader, epoch)\n",
    "    valid_loss, iou_score = valid_step(model, loss, valid_dataloader, epoch)\n",
    "    scheduler.step(valid_loss)\n",
    "\n",
    "    if WEIGHT_SAVER != \"nothing\" and valid_loss < best_loss and epoch > 3:\n",
    "        best_loss = valid_loss\n",
    "\n",
    "        print(f\"[{epoch}] Saved weights with IoU: {iou_score:.2f} | loss: {valid_loss:.4f}\")\n",
    "    \n",
    "        \n",
    "        if WEIGHT_SAVER == \"all\":\n",
    "            weights_path = f\"{TBpath}/weights_{epoch}.pth\"\n",
    "            model_path = f\"{TBpath}/model_{epoch}.onnx\"\n",
    "            optimizer_path = f\"{TBpath}/optimizer_{epoch}.pth\"\n",
    "            \n",
    "        elif WEIGHT_SAVER == \"last\":\n",
    "            weights_path = f\"{TBpath}/weights_last.pth\"\n",
    "            model_path =   f\"{TBpath}/model_last.onnx\"\n",
    "            optimizer_path = f\"{TBpath}/optimizer_last.pth\"\n",
    "\n",
    "        if \"TORCH\" in SAVE_METHOD:\n",
    "            torch.save(model.state_dict(), weights_path)\n",
    "        \n",
    "        if \"ONNX\" in SAVE_METHOD:\n",
    "            torch.onnx.export(model, torch.empty(size=(BATCH_SIZE, 3, *CROP_SIZE)), model_path)\n",
    "        \n",
    "\n",
    "\n",
    "    TBwriter.add_scalar('valid loss', valid_loss, epoch)\n",
    "    TBwriter.add_scalar('train loss', train_loss, epoch)\n",
    "    \n",
    "    TBwriter.add_scalar('IoU', iou_score, epoch)\n",
    "\n",
    "    epoch += 1\n",
    "    pbar.update()\n",
    "    pbar.set_description(\n",
    "        f'IoU: {iou_score:.2f}  | train/valid loss: {train_loss:.4f}/{valid_loss:.4f}')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-16T10:32:05.609078Z",
     "iopub.execute_input": "2023-05-16T10:32:05.609936Z",
     "iopub.status.idle": "2023-05-16T10:32:17.790992Z",
     "shell.execute_reply.started": "2023-05-16T10:32:05.609904Z",
     "shell.execute_reply": "2023-05-16T10:32:17.788282Z"
    },
    "trusted": true
   },
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "text": "  0%|          | 0/15 [00:00<?, ?it/s]",
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOutOfMemoryError\u001B[0m                          Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[19], line 8\u001B[0m\n\u001B[1;32m      5\u001B[0m pbar\u001B[38;5;241m.\u001B[39mupdate(epoch)\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m(epoch \u001B[38;5;241m<\u001B[39m EPOCHS):\n\u001B[0;32m----> 8\u001B[0m     train_loss \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      9\u001B[0m     valid_loss, iou_score \u001B[38;5;241m=\u001B[39m valid_step(model, loss, valid_dataloader, epoch)\n\u001B[1;32m     10\u001B[0m     scheduler\u001B[38;5;241m.\u001B[39mstep(valid_loss)\n",
      "Cell \u001B[0;32mIn[17], line 10\u001B[0m, in \u001B[0;36mtrain_step\u001B[0;34m(net, criterion, optimizer, dataloader, epoch)\u001B[0m\n\u001B[1;32m      6\u001B[0m labels \u001B[38;5;241m=\u001B[39m labels\u001B[38;5;241m.\u001B[39mto(DEVICE)\n\u001B[1;32m      8\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m---> 10\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[43mnet\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimages\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(output, labels)\n\u001B[1;32m     12\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Cell \u001B[0;32mIn[12], line 24\u001B[0m, in \u001B[0;36mUNet.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[0;32m---> 24\u001B[0m     x1 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     25\u001B[0m     x2 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdown1(x1)\n\u001B[1;32m     26\u001B[0m     x3 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdown2(x2)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Cell \u001B[0;32mIn[11], line 25\u001B[0m, in \u001B[0;36mDoubleConv.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[0;32m---> 25\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdouble_conv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 217\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py:463\u001B[0m, in \u001B[0;36mConv2d.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    462\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 463\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_conv_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py:459\u001B[0m, in \u001B[0;36mConv2d._conv_forward\u001B[0;34m(self, input, weight, bias)\u001B[0m\n\u001B[1;32m    455\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mzeros\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    456\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv2d(F\u001B[38;5;241m.\u001B[39mpad(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reversed_padding_repeated_twice, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode),\n\u001B[1;32m    457\u001B[0m                     weight, bias, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstride,\n\u001B[1;32m    458\u001B[0m                     _pair(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdilation, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups)\n\u001B[0;32m--> 459\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2d\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    460\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mOutOfMemoryError\u001B[0m: CUDA out of memory. Tried to allocate 5.37 GiB (GPU 0; 15.90 GiB total capacity; 11.21 GiB already allocated; 3.64 GiB free; 11.27 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ],
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 5.37 GiB (GPU 0; 15.90 GiB total capacity; 11.21 GiB already allocated; 3.64 GiB free; 11.27 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "test_transform = A.Compose(\n",
    "    [\n",
    "        A.Normalize(mean=NORMALIZE_MEAN_IMG, std=NORMALIZE_DEVIATIONS_IMG, always_apply=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_dataset = RoadsDataset(*TEST_SET,\n",
    "       class_rgb_values=CLASS_RGB_VALUES, transform=valid_transform, readyToNetwork=prepare_to_network)\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=36,\n",
    "    num_workers=NUM_WORKERS,\n",
    ")\n",
    "if not trained:\n",
    "    print(f\"Используется не обученная модель, происходит загрузка модели из {SAVED_MODEL_PATH}\")\n",
    "    model = None\n",
    "    if \"ONNX\" in SAVE_METHOD and model is None:\n",
    "        print(f\"Попытка импорта модели из onnx файла\")\n",
    "        try:\n",
    "            import onnx\n",
    "            model = onnx.load(SAVED_MODEL_PATH)\n",
    "        except:\n",
    "            pass\n",
    "    if \"TORCH\" in SAVE_METHOD and model is None:\n",
    "        print(f\"Попытка импорта модели из pth файла\")\n",
    "        model = UNet(3,2,bilinear=True)\n",
    "        model.state_dict(torch.load(f=SAVED_MODEL_PATH))\n",
    "\n",
    "    model.to(DEVICE)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-16T10:32:17.793904Z",
     "iopub.status.idle": "2023-05-16T10:32:17.796136Z",
     "shell.execute_reply.started": "2023-05-16T10:32:17.795892Z",
     "shell.execute_reply": "2023-05-16T10:32:17.795915Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def test_step(model, loader, metric : metrics.MulticlassStatScores):\n",
    "    classes = CLASS_NAMES\n",
    "    metric.to(DEVICE)\n",
    "\n",
    "    iou = metrics.JaccardIndex(task=\"multiclass\", num_classes=2).to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for id, (images, labels) in enumerate(loader):\n",
    "            images = images.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "            output = model(images)\n",
    "            TBwriter.add_figure('test_sample', create_image_plot(\n",
    "                origin=images[0].cpu().numpy().transpose(2, 1, 0),\n",
    "                true=colour_code_segmentation(reverse_one_hot(\n",
    "                    labels[0].cpu().numpy().transpose(2, 1, 0)), CLASS_RGB_VALUES),\n",
    "                pred=colour_code_segmentation(reverse_one_hot(\n",
    "                    output[0].cpu().numpy().transpose(2, 1, 0)), CLASS_RGB_VALUES)),\n",
    "                  id)\n",
    "            iou.update(output, labels)\n",
    "    return iou.compute().cpu()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-16T10:32:17.799897Z",
     "iopub.status.idle": "2023-05-16T10:32:17.802097Z",
     "shell.execute_reply.started": "2023-05-16T10:32:17.801858Z",
     "shell.execute_reply": "2023-05-16T10:32:17.801882Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "iou = test_step(model, test_dataloader)\n",
    "print(f\"IoU: {iou}\");\n",
    "TBwriter.close()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-16T10:32:17.804895Z",
     "iopub.status.idle": "2023-05-16T10:32:17.805615Z",
     "shell.execute_reply.started": "2023-05-16T10:32:17.805366Z",
     "shell.execute_reply": "2023-05-16T10:32:17.805404Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}
