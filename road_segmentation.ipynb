{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-18T01:41:19.768781900Z",
     "start_time": "2023-05-18T01:41:16.426756800Z"
    },
    "execution": {
     "iopub.execute_input": "2023-05-16T10:31:44.809652Z",
     "iopub.status.busy": "2023-05-16T10:31:44.809295Z",
     "iopub.status.idle": "2023-05-16T10:31:47.816812Z",
     "shell.execute_reply": "2023-05-16T10:31:47.815762Z",
     "shell.execute_reply.started": "2023-05-16T10:31:44.809623Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join as pjoin\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "import torchmetrics.classification as metrics\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import albumentations as A\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torchinfo\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-18T01:41:19.784606600Z",
     "start_time": "2023-05-18T01:41:19.772739900Z"
    },
    "execution": {
     "iopub.execute_input": "2023-05-16T10:31:47.818414Z",
     "iopub.status.busy": "2023-05-16T10:31:47.818059Z",
     "iopub.status.idle": "2023-05-16T10:31:47.831201Z",
     "shell.execute_reply": "2023-05-16T10:31:47.829980Z",
     "shell.execute_reply.started": "2023-05-16T10:31:47.818362Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join as pjoin\n",
    "import contextlib\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def uniqufy_path(path):\n",
    "    filename, extension = os.path.splitext(path)\n",
    "    file_index = 1\n",
    "\n",
    "    while os.path.exists(path):\n",
    "        path = f\"{filename}_{file_index}{extension}\"\n",
    "        file_index += 1\n",
    "    \n",
    "    return path\n",
    "\n",
    "def create_image_plot(row_len : int = None, figsize = (16,6), **images):\n",
    "    n_images = len(images)\n",
    "    if row_len is None:\n",
    "        row_len = n_images\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    for idx, (name, image) in enumerate(images.items()):\n",
    "        #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        ax = fig.add_subplot(n_images//row_len+1, row_len, idx+1)\n",
    "        ax.set_title(name.title(), fontsize=16)\n",
    "        with open(\"$null\", 'w') as dummy_f:\n",
    "            with contextlib.redirect_stderr(dummy_f):\n",
    "                ax.imshow(image)\n",
    "    return fig\n",
    "\n",
    "def save_imgs(path = None, name = \"imgs\", **images):\n",
    "    if(path is None):\n",
    "        raise AttributeError(f\"You shoud write path\")\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    image_path = pjoin(path, f\"{name}\")\n",
    "    fig = create_image_plot(**images)\n",
    "    fig.savefig(image_path)\n",
    "    fig.clear()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-18T01:41:19.815582700Z",
     "start_time": "2023-05-18T01:41:19.788020700Z"
    },
    "execution": {
     "iopub.execute_input": "2023-05-16T10:31:47.836245Z",
     "iopub.status.busy": "2023-05-16T10:31:47.835259Z",
     "iopub.status.idle": "2023-05-16T10:31:47.871485Z",
     "shell.execute_reply": "2023-05-16T10:31:47.870454Z",
     "shell.execute_reply.started": "2023-05-16T10:31:47.836206Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "LAUNCH_NAME = \"UNet_9\"\n",
    "\n",
    "\n",
    "STARTING_EPOCH = 0\n",
    "LOAD_WEIGHTS = None #\n",
    "LOAD_ADAM_STATE = None #\n",
    "USE_MANUAL_TENSORBOARD_FOLDER = None # \n",
    "\n",
    "SAVED_MODEL_PATH = None \n",
    "\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 1E-5 # 0.0001 \n",
    "WEIGHT_DECAY = 0 # 1E-7\n",
    "\n",
    "BATCH_SIZE = 10 # 20\n",
    "\n",
    "SAVE_METHOD = \"TORCH\" # \"TORCH\" / \"ONNX\"\n",
    "WEIGHT_SAVER = \"last\" # \"all\" / \"nothing\" / \"last\"\n",
    "\n",
    "CLASS_NAMES = ['other', 'road']\n",
    "CLASS_RGB_VALUES = [[0,0,0], [255, 255, 255]]\n",
    "\n",
    "NORMALIZE_MEAN_IMG =  [0.4295, 0.4325, 0.3961]       #[0.485, 0.456, 0.406]\n",
    "NORMALIZE_DEVIATIONS_IMG =  [0.2267, 0.2192, 0.2240] #[0.229, 0.224, 0.225]\n",
    " \n",
    "CROP_SIZE = (256, 256)\n",
    "\n",
    "NUM_WORKERS = 4\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "DATASET_DIR = './tiff'\n",
    "VALID_SET   = (pjoin(DATASET_DIR, \"val\"), pjoin(DATASET_DIR, \"val_labels\"))\n",
    "TEST_SET   =  (pjoin(DATASET_DIR, \"test\"), pjoin(DATASET_DIR, \"test_labels\"))\n",
    "TRAIN_SET   = (pjoin(DATASET_DIR, \"train\"), pjoin(DATASET_DIR, \"train_labels\"))\n",
    "\n",
    "trained = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-18T01:41:19.835703500Z",
     "start_time": "2023-05-18T01:41:19.815582700Z"
    },
    "execution": {
     "iopub.execute_input": "2023-05-16T10:31:47.873970Z",
     "iopub.status.busy": "2023-05-16T10:31:47.873332Z",
     "iopub.status.idle": "2023-05-16T10:31:47.886795Z",
     "shell.execute_reply": "2023-05-16T10:31:47.885819Z",
     "shell.execute_reply.started": "2023-05-16T10:31:47.873936Z"
    }
   },
   "outputs": [],
   "source": [
    "TBpath = uniqufy_path(f\"TB_cache/{LAUNCH_NAME}\") if USE_MANUAL_TENSORBOARD_FOLDER is None else USE_MANUAL_TENSORBOARD_FOLDER\n",
    "TBwriter = SummaryWriter(TBpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Transforms"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-18T01:41:19.857511500Z",
     "start_time": "2023-05-18T01:41:19.832679100Z"
    },
    "execution": {
     "iopub.execute_input": "2023-05-16T10:31:47.890407Z",
     "iopub.status.busy": "2023-05-16T10:31:47.890138Z",
     "iopub.status.idle": "2023-05-16T10:31:47.900460Z",
     "shell.execute_reply": "2023-05-16T10:31:47.899580Z",
     "shell.execute_reply.started": "2023-05-16T10:31:47.890368Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_tensor(x, **kwargs):\n",
    "    return x.transpose(2, 0, 1).astype('float32')\n",
    "\n",
    "prepare_to_network = A.Lambda(image=to_tensor, mask=to_tensor)\n",
    "\n",
    "train_transform = A.Compose(\n",
    "    [\n",
    "        A.OneOf(\n",
    "            [\n",
    "                A.HorizontalFlip(p=1),\n",
    "                A.VerticalFlip(p=1),\n",
    "                A.RandomRotate90(p=1),\n",
    "            ],\n",
    "            p=0.75,\n",
    "        ),\n",
    "        A.Normalize(mean=NORMALIZE_MEAN_IMG, std=NORMALIZE_DEVIATIONS_IMG, always_apply=True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "valid_transform = A.Compose(\n",
    "    [\n",
    "        A.Normalize(mean=NORMALIZE_MEAN_IMG, std=NORMALIZE_DEVIATIONS_IMG, always_apply=True),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Sub functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-18T01:41:19.861499700Z",
     "start_time": "2023-05-18T01:41:19.848512300Z"
    },
    "execution": {
     "iopub.execute_input": "2023-05-16T10:31:47.903033Z",
     "iopub.status.busy": "2023-05-16T10:31:47.902412Z",
     "iopub.status.idle": "2023-05-16T10:31:47.910278Z",
     "shell.execute_reply": "2023-05-16T10:31:47.909327Z",
     "shell.execute_reply.started": "2023-05-16T10:31:47.902994Z"
    }
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(label, label_values):\n",
    "    semantic_map = []\n",
    "    for colour in label_values:\n",
    "        equality = np.equal(label, colour)\n",
    "        class_map = np.all(equality, axis = -1)\n",
    "        semantic_map.append(class_map)\n",
    "    semantic_map = np.stack(semantic_map, axis=-1)\n",
    "    return semantic_map\n",
    "\n",
    "def reverse_one_hot(image):\n",
    "    x = np.argmax(image, axis = -1)\n",
    "    return x\n",
    "\n",
    "def colour_code_segmentation(image, label_values):\n",
    "    colour_codes = np.array(label_values)\n",
    "    x = colour_codes[image.astype(int)]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset class"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-18T01:41:19.882245Z",
     "start_time": "2023-05-18T01:41:19.865493300Z"
    },
    "execution": {
     "iopub.execute_input": "2023-05-16T10:31:47.912204Z",
     "iopub.status.busy": "2023-05-16T10:31:47.911836Z",
     "iopub.status.idle": "2023-05-16T10:31:47.925353Z",
     "shell.execute_reply": "2023-05-16T10:31:47.924297Z",
     "shell.execute_reply.started": "2023-05-16T10:31:47.912172Z"
    }
   },
   "outputs": [],
   "source": [
    "class RoadsDataset(Dataset):\n",
    "    def __init__(self, values_dir, labels_dir, class_rgb_values=None, transform=None, readyToNetwork=None):\n",
    "        self.values_dir = values_dir\n",
    "        self.labels_dir = labels_dir\n",
    "        self.class_rgb_values = class_rgb_values\n",
    "        self.images = [pjoin(self.values_dir, filename) for filename in sorted(os.listdir(self.values_dir))]\n",
    "        self.labels = [pjoin(self.labels_dir, filename) for filename in sorted(os.listdir(self.labels_dir))]\n",
    "        self.transform = transform\n",
    "        self.readyToNetwork = readyToNetwork\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.images[index]\n",
    "        label_path = self.labels[index]\n",
    "\n",
    "        image = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n",
    "        label = cv2.cvtColor(cv2.imread(label_path), cv2.COLOR_BGR2RGB)\n",
    "        label = one_hot_encode(label, self.class_rgb_values).astype('float')\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(image=image, mask=label)\n",
    "            image, label = sample['image'], sample['mask']\n",
    "        if self.readyToNetwork:\n",
    "            sample = self.readyToNetwork(image=image, mask=label)\n",
    "            image, label = sample['image'], sample['mask']\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-18T01:41:21.421635Z",
     "start_time": "2023-05-18T01:41:19.878290200Z"
    },
    "execution": {
     "iopub.execute_input": "2023-05-16T10:31:47.927368Z",
     "iopub.status.busy": "2023-05-16T10:31:47.926854Z",
     "iopub.status.idle": "2023-05-16T10:31:58.033961Z",
     "shell.execute_reply": "2023-05-16T10:31:58.013385Z",
     "shell.execute_reply.started": "2023-05-16T10:31:47.927338Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_dataset = RoadsDataset(*TEST_SET,\n",
    "                       class_rgb_values=CLASS_RGB_VALUES, transform=valid_transform)\n",
    "\n",
    "for i in range(10):\n",
    "    image, mask = sample_dataset[np.random.randint(0, len(sample_dataset))]\n",
    "    TBwriter.add_figure(f'train samples', create_image_plot(origin=image, true=colour_code_segmentation(\n",
    "        reverse_one_hot(mask), CLASS_RGB_VALUES)), global_step=i)\n",
    "del(sample_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# UNet parts"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-18T01:41:21.436594600Z",
     "start_time": "2023-05-18T01:41:21.420638Z"
    },
    "execution": {
     "iopub.execute_input": "2023-05-16T10:31:58.039190Z",
     "iopub.status.busy": "2023-05-16T10:31:58.038632Z",
     "iopub.status.idle": "2023-05-16T10:31:58.055468Z",
     "shell.execute_reply": "2023-05-16T10:31:58.054424Z",
     "shell.execute_reply.started": "2023-05-16T10:31:58.039151Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" Parts of the U-Net model \"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](u-net-architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Модель"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-18T01:41:21.455238400Z",
     "start_time": "2023-05-18T01:41:21.431608800Z"
    },
    "execution": {
     "iopub.execute_input": "2023-05-16T10:31:58.057380Z",
     "iopub.status.busy": "2023-05-16T10:31:58.056976Z",
     "iopub.status.idle": "2023-05-16T10:31:58.070318Z",
     "shell.execute_reply": "2023-05-16T10:31:58.069440Z",
     "shell.execute_reply.started": "2023-05-16T10:31:58.057348Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" Full assembly of the parts to form the complete network \"\"\"\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=False):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = (DoubleConv(n_channels, 64))\n",
    "        self.down1 = (Down(64, 128))\n",
    "        self.down2 = (Down(128, 256))\n",
    "        self.down3 = (Down(256, 512))\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = (Down(512, 1024 // factor))\n",
    "        self.up1 = (Up(1024, 512 // factor, bilinear))\n",
    "        self.up2 = (Up(512, 256 // factor, bilinear))\n",
    "        self.up3 = (Up(256, 128 // factor, bilinear))\n",
    "        self.up4 = (Up(128, 64, bilinear))\n",
    "        self.outc = (OutConv(64, n_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-18T01:41:21.570240200Z",
     "start_time": "2023-05-18T01:41:21.447260200Z"
    },
    "execution": {
     "iopub.execute_input": "2023-05-16T10:31:58.074483Z",
     "iopub.status.busy": "2023-05-16T10:31:58.073532Z",
     "iopub.status.idle": "2023-05-16T10:31:58.231481Z",
     "shell.execute_reply": "2023-05-16T10:31:58.230450Z",
     "shell.execute_reply.started": "2023-05-16T10:31:58.074456Z"
    }
   },
   "outputs": [],
   "source": [
    "model = UNet(3,2,bilinear=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataloaders"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-18T01:41:21.766292800Z",
     "start_time": "2023-05-18T01:41:21.541318300Z"
    },
    "execution": {
     "iopub.execute_input": "2023-05-16T10:31:58.234978Z",
     "iopub.status.busy": "2023-05-16T10:31:58.233993Z",
     "iopub.status.idle": "2023-05-16T10:31:58.524866Z",
     "shell.execute_reply": "2023-05-16T10:31:58.523909Z",
     "shell.execute_reply.started": "2023-05-16T10:31:58.234939Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = RoadsDataset(*TRAIN_SET,\n",
    "                       class_rgb_values=CLASS_RGB_VALUES, transform=train_transform, readyToNetwork=prepare_to_network)\n",
    "valid_dataset = RoadsDataset(*VALID_SET,\n",
    "                       class_rgb_values=CLASS_RGB_VALUES, transform=valid_transform, readyToNetwork=prepare_to_network)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    ")\n",
    "valid_dataloader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=BATCH_SIZE//4,\n",
    "    num_workers=NUM_WORKERS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model information"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-18T01:41:25.079277400Z",
     "start_time": "2023-05-18T01:41:21.762304100Z"
    },
    "execution": {
     "iopub.execute_input": "2023-05-16T10:31:58.527951Z",
     "iopub.status.busy": "2023-05-16T10:31:58.527587Z",
     "iopub.status.idle": "2023-05-16T10:32:05.568288Z",
     "shell.execute_reply": "2023-05-16T10:32:05.567354Z",
     "shell.execute_reply.started": "2023-05-16T10:31:58.527917Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================================================================================================================================================\n",
      "Layer (type (var_name))                       Input Shape               Output Shape              Param #                   Param %                   Kernel Shape              Mult-Adds                 Trainable\n",
      "============================================================================================================================================================================================================================\n",
      "UNet (UNet)                                   [10, 3, 256, 256]         [10, 2, 256, 256]         --                             --                   --                        --                        True\n",
      "├─DoubleConv (inc)                            [10, 3, 256, 256]         [10, 64, 256, 256]        --                             --                   --                        --                        True\n",
      "│    └─Sequential (double_conv)               [10, 3, 256, 256]         [10, 64, 256, 256]        --                             --                   --                        --                        True\n",
      "│    │    └─Conv2d (0)                        [10, 3, 256, 256]         [10, 64, 256, 256]        1,728                       0.01%                   [3, 3]                    1,132,462,080             True\n",
      "│    │    └─BatchNorm2d (1)                   [10, 64, 256, 256]        [10, 64, 256, 256]        128                         0.00%                   --                        1,280                     True\n",
      "│    │    └─ReLU (2)                          [10, 64, 256, 256]        [10, 64, 256, 256]        --                             --                   --                        --                        --\n",
      "│    │    └─Conv2d (3)                        [10, 64, 256, 256]        [10, 64, 256, 256]        36,864                      0.21%                   [3, 3]                    24,159,191,040            True\n",
      "│    │    └─BatchNorm2d (4)                   [10, 64, 256, 256]        [10, 64, 256, 256]        128                         0.00%                   --                        1,280                     True\n",
      "│    │    └─ReLU (5)                          [10, 64, 256, 256]        [10, 64, 256, 256]        --                             --                   --                        --                        --\n",
      "├─Down (down1)                                [10, 64, 256, 256]        [10, 128, 128, 128]       --                             --                   --                        --                        True\n",
      "│    └─Sequential (maxpool_conv)              [10, 64, 256, 256]        [10, 128, 128, 128]       --                             --                   --                        --                        True\n",
      "│    │    └─MaxPool2d (0)                     [10, 64, 256, 256]        [10, 64, 128, 128]        --                             --                   2                         --                        --\n",
      "│    │    └─DoubleConv (1)                    [10, 64, 128, 128]        [10, 128, 128, 128]       221,696                     1.28%                   --                        36,238,791,680            True\n",
      "├─Down (down2)                                [10, 128, 128, 128]       [10, 256, 64, 64]         --                             --                   --                        --                        True\n",
      "│    └─Sequential (maxpool_conv)              [10, 128, 128, 128]       [10, 256, 64, 64]         --                             --                   --                        --                        True\n",
      "│    │    └─MaxPool2d (0)                     [10, 128, 128, 128]       [10, 128, 64, 64]         --                             --                   2                         --                        --\n",
      "│    │    └─DoubleConv (1)                    [10, 128, 64, 64]         [10, 256, 64, 64]         885,760                     5.13%                   --                        36,238,796,800            True\n",
      "├─Down (down3)                                [10, 256, 64, 64]         [10, 512, 32, 32]         --                             --                   --                        --                        True\n",
      "│    └─Sequential (maxpool_conv)              [10, 256, 64, 64]         [10, 512, 32, 32]         --                             --                   --                        --                        True\n",
      "│    │    └─MaxPool2d (0)                     [10, 256, 64, 64]         [10, 256, 32, 32]         --                             --                   2                         --                        --\n",
      "│    │    └─DoubleConv (1)                    [10, 256, 32, 32]         [10, 512, 32, 32]         3,540,992                  20.51%                   --                        36,238,807,040            True\n",
      "├─Down (down4)                                [10, 512, 32, 32]         [10, 512, 16, 16]         --                             --                   --                        --                        True\n",
      "│    └─Sequential (maxpool_conv)              [10, 512, 32, 32]         [10, 512, 16, 16]         --                             --                   --                        --                        True\n",
      "│    │    └─MaxPool2d (0)                     [10, 512, 32, 32]         [10, 512, 16, 16]         --                             --                   2                         --                        --\n",
      "│    │    └─DoubleConv (1)                    [10, 512, 16, 16]         [10, 512, 16, 16]         4,720,640                  27.35%                   --                        12,079,616,000            True\n",
      "├─Up (up1)                                    [10, 512, 16, 16]         [10, 256, 32, 32]         --                             --                   --                        --                        True\n",
      "│    └─Upsample (up)                          [10, 512, 16, 16]         [10, 512, 32, 32]         --                             --                   --                        --                        --\n",
      "│    └─DoubleConv (conv)                      [10, 1024, 32, 32]        [10, 256, 32, 32]         --                             --                   --                        --                        True\n",
      "│    │    └─Sequential (double_conv)          [10, 1024, 32, 32]        [10, 256, 32, 32]         5,899,776                  34.18%                   --                        60,397,992,960            True\n",
      "├─Up (up2)                                    [10, 256, 32, 32]         [10, 128, 64, 64]         --                             --                   --                        --                        True\n",
      "│    └─Upsample (up)                          [10, 256, 32, 32]         [10, 256, 64, 64]         --                             --                   --                        --                        --\n",
      "│    └─DoubleConv (conv)                      [10, 512, 64, 64]         [10, 128, 64, 64]         --                             --                   --                        --                        True\n",
      "│    │    └─Sequential (double_conv)          [10, 512, 64, 64]         [10, 128, 64, 64]         1,475,328                   8.55%                   --                        60,397,985,280            True\n",
      "├─Up (up3)                                    [10, 128, 64, 64]         [10, 64, 128, 128]        --                             --                   --                        --                        True\n",
      "│    └─Upsample (up)                          [10, 128, 64, 64]         [10, 128, 128, 128]       --                             --                   --                        --                        --\n",
      "│    └─DoubleConv (conv)                      [10, 256, 128, 128]       [10, 64, 128, 128]        --                             --                   --                        --                        True\n",
      "│    │    └─Sequential (double_conv)          [10, 256, 128, 128]       [10, 64, 128, 128]        369,024                     2.14%                   --                        60,397,981,440            True\n",
      "├─Up (up4)                                    [10, 64, 128, 128]        [10, 64, 256, 256]        --                             --                   --                        --                        True\n",
      "│    └─Upsample (up)                          [10, 64, 128, 128]        [10, 64, 256, 256]        --                             --                   --                        --                        --\n",
      "│    └─DoubleConv (conv)                      [10, 128, 256, 256]       [10, 64, 256, 256]        --                             --                   --                        --                        True\n",
      "│    │    └─Sequential (double_conv)          [10, 128, 256, 256]       [10, 64, 256, 256]        110,848                     0.64%                   --                        72,477,575,680            True\n",
      "├─OutConv (outc)                              [10, 64, 256, 256]        [10, 2, 256, 256]         --                             --                   --                        --                        True\n",
      "│    └─Conv2d (conv)                          [10, 64, 256, 256]        [10, 2, 256, 256]         130                         0.00%                   [1, 1]                    85,196,800                True\n",
      "============================================================================================================================================================================================================================\n",
      "Total params: 17,263,042\n",
      "Trainable params: 17,263,042\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 399.84\n",
      "============================================================================================================================================================================================================================\n",
      "Input size (MB): 7.86\n",
      "Forward/backward pass size (MB): 4791.99\n",
      "Params size (MB): 69.05\n",
      "Estimated Total Size (MB): 4868.91\n",
      "============================================================================================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# images, _ = next(iter(valid_dataloader))\n",
    "# TBwriter.add_graph(model, images)\n",
    "\n",
    "if \"ONNX\" in SAVE_METHOD:\n",
    "    model_path = f\"{TBpath}/model_first.onnx\"\n",
    "    torch.onnx.export(model, torch.empty(size=(BATCH_SIZE, 3, *CROP_SIZE)), model_path)\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "print(model_sum := torchinfo.summary(model, input_size=(BATCH_SIZE, 3, *CROP_SIZE), row_settings=[\"var_names\"], verbose=0, col_names=[\n",
    "      \"input_size\", \"output_size\", \"num_params\", \"params_percent\", \"kernel_size\", \"mult_adds\", \"trainable\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loss optimizer and scheduler"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-18T01:41:25.123894900Z",
     "start_time": "2023-05-18T01:41:25.082269500Z"
    },
    "execution": {
     "iopub.execute_input": "2023-05-16T10:32:05.570593Z",
     "iopub.status.busy": "2023-05-16T10:32:05.569904Z",
     "iopub.status.idle": "2023-05-16T10:32:05.577560Z",
     "shell.execute_reply": "2023-05-16T10:32:05.576612Z",
     "shell.execute_reply.started": "2023-05-16T10:32:05.570542Z"
    }
   },
   "outputs": [],
   "source": [
    "loss = smp.losses.DiceLoss(mode='binary')\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                              lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=3, threshold=1e-3, cooldown=1, factor=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train and Valid steps"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-18T01:41:25.131873400Z",
     "start_time": "2023-05-18T01:41:25.095745700Z"
    },
    "execution": {
     "iopub.execute_input": "2023-05-16T10:32:05.579291Z",
     "iopub.status.busy": "2023-05-16T10:32:05.578787Z",
     "iopub.status.idle": "2023-05-16T10:32:05.593681Z",
     "shell.execute_reply": "2023-05-16T10:32:05.592799Z",
     "shell.execute_reply.started": "2023-05-16T10:32:05.579259Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_step(net, criterion, optimizer, dataloader, epoch: int = None):\n",
    "    net.train()\n",
    "    running_loss = 0.\n",
    "    for images, labels in dataloader:\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = net(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss\n",
    "\n",
    "    with torch.no_grad():\n",
    "        train_loss = running_loss / len(dataloader)\n",
    "    return train_loss.item()\n",
    "\n",
    "\n",
    "def valid_step(net, criterion, dataloader, epoch: int = None):\n",
    "    net.eval()\n",
    "    running_loss = 0.\n",
    "    IoU = metrics.BinaryJaccardIndex()\n",
    "    IoU.to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for step, (images, labels) in enumerate(dataloader):\n",
    "            images = images.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "\n",
    "            output = net(images)\n",
    "\n",
    "            IoU(output, labels)\n",
    "            loss = criterion(output, labels)\n",
    "            running_loss += loss\n",
    "\n",
    "            save_imgs(pjoin(TBpath, f\"valid_samples/samples_{epoch}\"), name=f\"img_{step}\",\n",
    "                origin=images[0].cpu().numpy().transpose(2, 1, 0),\n",
    "                true=colour_code_segmentation(reverse_one_hot(\n",
    "                    labels[0].cpu().numpy().transpose(2, 1, 0)), CLASS_RGB_VALUES),\n",
    "                pred=colour_code_segmentation(reverse_one_hot(\n",
    "                    output[0].cpu().numpy().transpose(2, 1, 0)), CLASS_RGB_VALUES))\n",
    "\n",
    "        TBwriter.add_figure('valid_sample', create_image_plot(\n",
    "                origin=images[0].cpu().numpy().transpose(2, 1, 0),\n",
    "                true=colour_code_segmentation(reverse_one_hot(\n",
    "                    labels[0].cpu().numpy().transpose(2, 1, 0)), CLASS_RGB_VALUES),\n",
    "                pred=colour_code_segmentation(reverse_one_hot(\n",
    "                    output[0].cpu().numpy().transpose(2, 1, 0)), CLASS_RGB_VALUES)),\n",
    "                  epoch)\n",
    "\n",
    "        valid_loss = running_loss / len(valid_dataloader)\n",
    "\n",
    "        return valid_loss.item(), IoU.compute().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-18T01:41:25.131873400Z",
     "start_time": "2023-05-18T01:41:25.112794700Z"
    },
    "execution": {
     "iopub.execute_input": "2023-05-16T10:32:05.595309Z",
     "iopub.status.busy": "2023-05-16T10:32:05.594763Z",
     "iopub.status.idle": "2023-05-16T10:32:05.607525Z",
     "shell.execute_reply": "2023-05-16T10:32:05.606695Z",
     "shell.execute_reply.started": "2023-05-16T10:32:05.595278Z"
    }
   },
   "outputs": [],
   "source": [
    "epoch = STARTING_EPOCH"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train loop"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-18T01:41:25.130876300Z"
    },
    "execution": {
     "iopub.execute_input": "2023-05-16T10:32:05.609936Z",
     "iopub.status.busy": "2023-05-16T10:32:05.609078Z",
     "iopub.status.idle": "2023-05-16T10:32:17.790992Z",
     "shell.execute_reply": "2023-05-16T10:32:17.788282Z",
     "shell.execute_reply.started": "2023-05-16T10:32:05.609904Z"
    },
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IoU: 0.94  | train/valid loss: 0.0518/0.0517:  50%|█████     | 5/10 [1:13:10<1:11:59, 863.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] Saved weights with IoU: 0.94 | loss: 0.0517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IoU: 0.94  | train/valid loss: 0.0381/0.0407:  60%|██████    | 6/10 [1:27:28<57:27, 861.79s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5] Saved weights with IoU: 0.94 | loss: 0.0407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IoU: 0.94  | train/valid loss: 0.0310/0.0358:  70%|███████   | 7/10 [1:41:38<42:53, 857.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6] Saved weights with IoU: 0.94 | loss: 0.0358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IoU: 0.94  | train/valid loss: 0.0272/0.0341:  80%|████████  | 8/10 [1:55:53<28:34, 857.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7] Saved weights with IoU: 0.94 | loss: 0.0341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IoU: 0.94  | train/valid loss: 0.0253/0.0325:  90%|█████████ | 9/10 [2:10:04<14:15, 855.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8] Saved weights with IoU: 0.94 | loss: 0.0325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IoU: 0.94  | train/valid loss: 0.0243/0.0316: 100%|██████████| 10/10 [2:24:37<00:00, 860.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9] Saved weights with IoU: 0.94 | loss: 0.0316\n"
     ]
    }
   ],
   "source": [
    "best_loss = 10000\n",
    "trained = True\n",
    "\n",
    "pbar = tqdm(range(EPOCHS))\n",
    "pbar.update(epoch)\n",
    "\n",
    "while(epoch < EPOCHS):\n",
    "    train_loss = train_step(model, loss, optimizer, train_dataloader, epoch)\n",
    "    valid_loss, iou_score = valid_step(model, loss, valid_dataloader, epoch)\n",
    "    scheduler.step(valid_loss)\n",
    "\n",
    "    if WEIGHT_SAVER != \"nothing\" and valid_loss < best_loss and epoch > 3:\n",
    "        best_loss = valid_loss\n",
    "\n",
    "        print(f\"[{epoch}] Saved weights with IoU: {iou_score:.2f} | loss: {valid_loss:.4f}\")\n",
    "    \n",
    "        \n",
    "        if WEIGHT_SAVER == \"all\":\n",
    "            weights_path = f\"{TBpath}/weights_{epoch}.pth\"\n",
    "            model_path = f\"{TBpath}/model_{epoch}.onnx\"\n",
    "            optimizer_path = f\"{TBpath}/optimizer_{epoch}.pth\"\n",
    "            \n",
    "        elif WEIGHT_SAVER == \"last\":\n",
    "            weights_path = f\"{TBpath}/weights_last.pth\"\n",
    "            model_path =   f\"{TBpath}/model_last.onnx\"\n",
    "            optimizer_path = f\"{TBpath}/optimizer_last.pth\"\n",
    "\n",
    "        if \"TORCH\" in SAVE_METHOD:\n",
    "            torch.save(model.state_dict(), weights_path)\n",
    "        \n",
    "        if \"ONNX\" in SAVE_METHOD:\n",
    "            torch.onnx.export(model, torch.empty(size=(BATCH_SIZE, 3, *CROP_SIZE)), model_path)\n",
    "        \n",
    "\n",
    "\n",
    "    TBwriter.add_scalar('valid loss', valid_loss, epoch)\n",
    "    TBwriter.add_scalar('train loss', train_loss, epoch)\n",
    "    \n",
    "    TBwriter.add_scalar('IoU', iou_score, epoch)\n",
    "\n",
    "    epoch += 1\n",
    "    pbar.update()\n",
    "    pbar.set_description(\n",
    "        f'IoU: {iou_score:.2f}  | train/valid loss: {train_loss:.4f}/{valid_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test dataloader and load model if not trained"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-16T10:32:17.793904Z",
     "iopub.status.idle": "2023-05-16T10:32:17.796136Z",
     "shell.execute_reply": "2023-05-16T10:32:17.795915Z",
     "shell.execute_reply.started": "2023-05-16T10:32:17.795892Z"
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "test_transform = A.Compose(\n",
    "    [\n",
    "        A.Normalize(mean=NORMALIZE_MEAN_IMG, std=NORMALIZE_DEVIATIONS_IMG, always_apply=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_dataset = RoadsDataset(*TEST_SET,\n",
    "       class_rgb_values=CLASS_RGB_VALUES, transform=valid_transform, readyToNetwork=prepare_to_network)\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=36,\n",
    "    num_workers=NUM_WORKERS,\n",
    ")\n",
    "if not trained:\n",
    "    print(f\"Используется не обученная модель, происходит загрузка модели из {SAVED_MODEL_PATH}\")\n",
    "    model = None\n",
    "    if \"ONNX\" in SAVE_METHOD and model is None:\n",
    "        print(f\"Попытка импорта модели из onnx файла\")\n",
    "        try:\n",
    "            import onnx\n",
    "            model = onnx.load(SAVED_MODEL_PATH)\n",
    "        except:\n",
    "            pass\n",
    "    if \"TORCH\" in SAVE_METHOD and model is None:\n",
    "        print(f\"Попытка импорта модели из pth файла\")\n",
    "        model = UNet(3,2,bilinear=True)\n",
    "        model.state_dict(torch.load(f=SAVED_MODEL_PATH))\n",
    "\n",
    "    model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test step"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-16T10:32:17.799897Z",
     "iopub.status.idle": "2023-05-16T10:32:17.802097Z",
     "shell.execute_reply": "2023-05-16T10:32:17.801882Z",
     "shell.execute_reply.started": "2023-05-16T10:32:17.801858Z"
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "def test_step(model, loader):\n",
    "    classes = CLASS_NAMES\n",
    "\n",
    "    iou = metrics.JaccardIndex(task=\"binary\", num_classes=2).to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        model.to(DEVICE)\n",
    "        for id, (images, labels) in enumerate(loader):\n",
    "            images = images.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "            output = model(images)\n",
    "            TBwriter.add_figure('test_sample', create_image_plot(\n",
    "                origin=images[0].cpu().numpy().transpose(2, 1, 0),\n",
    "                true=colour_code_segmentation(reverse_one_hot(\n",
    "                    labels[0].cpu().numpy().transpose(2, 1, 0)), CLASS_RGB_VALUES),\n",
    "                pred=colour_code_segmentation(reverse_one_hot(\n",
    "                    output[0].cpu().numpy().transpose(2, 1, 0)), CLASS_RGB_VALUES)),\n",
    "                  id)\n",
    "            iou.update(output, labels)\n",
    "    return iou.compute()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](images.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-16T10:32:17.804895Z",
     "iopub.status.idle": "2023-05-16T10:32:17.805615Z",
     "shell.execute_reply": "2023-05-16T10:32:17.805404Z",
     "shell.execute_reply.started": "2023-05-16T10:32:17.805366Z"
    },
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IoU: 0.9603548049926758\n"
     ]
    }
   ],
   "source": [
    "iou = test_step(model, test_dataloader)\n",
    "print(f\"IoU: {iou}\")\n",
    "TBwriter.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
